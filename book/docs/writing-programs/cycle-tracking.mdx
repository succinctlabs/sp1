import Example from "@site/static/examples_cycle-tracking_program_bin_normal.rs.mdx";

# Cycle Tracking

When writing a program, it is useful to know how many RISC-V cycles a portion of the program takes to identify potential performance bottlenecks. SP1 provides a way to track the number of cycles spent in a portion of the program.

## Tracking Cycles with Annotations

SP1 provides two methods to track cycle usage in your program:

1. Using print statements:
   ```rust
   #![no_main]
   sp1_zkvm::entrypoint!(main);

   fn main() {
        let mut nums = vec![1, 1];

        // Compute the sum of the numbers.
        println!("cycle-tracker-start: compute");
        let sum: u64 = nums.iter().sum();
        println!("cycle-tracker-end: compute");

        // Print the result.
        println!("result: {}", sum);
   }
   ```

   To save the cycle counts to the `ExecutionReport`, you can use the `cycle_tracker_report_start` and `cycle_tracker_report_end` annotations.

   ```rust
   #![no_main]
   sp1_zkvm::entrypoint!(main);

   fn main() {
        let mut nums = vec![1, 1];

        // Compute the sum of the numbers.
        println!("cycle-tracker-report-start: compute");
        let sum: u64 = nums.iter().sum();
        println!("cycle-tracker-report-end: compute");

        // Print the result.
        println!("result: {}", sum);
   }
   ```

   To read from tracked cycles from the `ExecutionReport`, you can read from the `cycle_tracker` map after executing the program.

   ```rust
   let report = client.execute(ELF, &stdin).run().unwrap();
   let cycle_count = report.cycle_tracker.get("compute").unwrap();
   println!("compute cycle count: {}", cycle_count);
   ```

2. Using the cycle tracker macro:
   ```rust 
   #![no_main]
   sp1_zkvm::entrypoint!(main);

   #[sp1_derive::cycle_tracker]
    pub fn expensive_function(x: usize) -> usize {
        let mut y = 1;
        for _ in 0..100 {
            y *= x;
            y %= 7919;
        }
        y
    }
   ```

   To use the cycle tracker macro, add `sp1-derive` to your program's dependencies:

   ```toml
   sp1-derive = "4.0.0"
   ```

### Get Tracked Cycle Counts

To include tracked cycle counts in the `ExecutionReport` when using `ProverClient::execute`, use the following annotations:

```rust
fn main() {
  println!("cycle-tracker-report-start: block name");
  // ...
  println!("cycle-tracker-report-end: block name");
}
```

This will log the cycle count for `block name` and include it in the `ExecutionReport` in the `cycle_tracker` map.

### Profiling a ZKVM program

Profiling a zkVM program produces a useful visualization ([example profile](https://share.firefox.dev/3Om1pzz)) which makes it easy to examine program performance and see exactly where VM cycles are being spent without needing to modify the program at all.

To profile a program, you need to:

1. Enable the profiling feature for `sp1-sdk` in `script/Cargo.toml`
2. Set the env variable `TRACE_FILE=trace.json` and then call `ProverClient::execute()` in your script.

If you're executing a larger program (>100M cycles), you should set `TRACE_SAMPLE_RATE` to reduce the size of the trace file. A sample rate of `1000` means that 1 in every 1000 VM cycles is sampled. By default, every cycle is sampled.

Many examples can be found in the repo, such as this ['fibonacci'](https://github.com/succinctlabs/sp1/blob/dev/examples/fibonacci/script/src/main.rs#L22) script.

Once you have your script it should look like the following:

```rs
    // Execute the program using the `ProverClient.execute` method, without generating a proof.
    let (_, report) = client.execute(ELF, &stdin).run().unwrap();
```

As well you must enable the profiling feature on the SDK:

```toml
    sp1-sdk = { version = "4.0.0", features = ["profiling"] }
```

The `TRACE_FILE` env var tells the executor where to save the profile, and the `TRACE_SAMPLE_RATE` env var tells the executor how often to sample the program.
A larger sample rate will give you a smaller profile, it is the number of instructions in between each sample.

The full command to profile should look something like this

```sh
    TRACE_FILE=output.json TRACE_SAMPLE_RATE=100 cargo run ...
```

To view these profiles, we recommend [Samply](https://github.com/mstange/samply).

```sh
    cargo install --locked samply
    samply load output.json
```

Samply uses the Firefox profiler to create a nice visualization of your programs execution.
![An example screenshot of the Firefox Profiler](@site/static/profiling.png)

#### Interpreting the Profile

- The "time" measurement in the profiler is actually the number of cycles spent,
  in general the less cycles for a given callframe the better.

- The CPU usage of the program will always be constant, as its running in the VM which is single threaded.
